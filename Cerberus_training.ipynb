{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Left_3.5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNJmV+yPb/omm8hxUuErmFi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamuelAmrich/TLEIA-TLEOS/blob/master/ML_Left_Cerberus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9B5jFy4XGM-",
        "colab_type": "text"
      },
      "source": [
        "**Príprava mašiny**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIu_Ilq674hz",
        "colab_type": "code",
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ffffc4f6-fa69-4924-83a3-5cba6e58ee91"
      },
      "source": [
        "#@title Default title text\n",
        "# Nainstalovanie potrebnych dodatocnych kniznic\n",
        "\n",
        "!pip3 install --upgrade pip\n",
        "\n",
        "!pip3 install tensorflow\n",
        "!pip3 install keras\n",
        "!pip3 install opencv-python\n",
        "\n",
        "!pip install split-folders\n",
        "!pip install -q pyyaml h5py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/84/23ed6a1796480a6f1a2d38f2802901d078266bda38388954d01d3f2e821d/pip-20.1.1-py2.py3-none-any.whl (1.5MB)\n",
            "\r\u001b[K     |▏                               | 10kB 19.3MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 2.1MB/s eta 0:00:01\r\u001b[K     |▋                               | 30kB 2.8MB/s eta 0:00:01\r\u001b[K     |▉                               | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |█                               | 51kB 2.5MB/s eta 0:00:01\r\u001b[K     |█▎                              | 61kB 2.7MB/s eta 0:00:01\r\u001b[K     |█▌                              | 71kB 3.1MB/s eta 0:00:01\r\u001b[K     |█▊                              | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |██                              | 92kB 3.5MB/s eta 0:00:01\r\u001b[K     |██▏                             | 102kB 3.5MB/s eta 0:00:01\r\u001b[K     |██▍                             | 112kB 3.5MB/s eta 0:00:01\r\u001b[K     |██▋                             | 122kB 3.5MB/s eta 0:00:01\r\u001b[K     |██▉                             | 133kB 3.5MB/s eta 0:00:01\r\u001b[K     |███                             | 143kB 3.5MB/s eta 0:00:01\r\u001b[K     |███▎                            | 153kB 3.5MB/s eta 0:00:01\r\u001b[K     |███▌                            | 163kB 3.5MB/s eta 0:00:01\r\u001b[K     |███▊                            | 174kB 3.5MB/s eta 0:00:01\r\u001b[K     |████                            | 184kB 3.5MB/s eta 0:00:01\r\u001b[K     |████▏                           | 194kB 3.5MB/s eta 0:00:01\r\u001b[K     |████▍                           | 204kB 3.5MB/s eta 0:00:01\r\u001b[K     |████▋                           | 215kB 3.5MB/s eta 0:00:01\r\u001b[K     |████▉                           | 225kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 235kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 245kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 256kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 266kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 276kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 286kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 296kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 307kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 317kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 327kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 337kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 348kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 358kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 368kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 378kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 389kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 399kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 409kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████                       | 419kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 430kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 440kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 450kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 460kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 471kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 481kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 491kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 501kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 512kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 522kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 532kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 542kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 552kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 563kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 573kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 583kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 593kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 604kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 614kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 624kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 634kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 645kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 655kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 665kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 675kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 686kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 696kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 706kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 716kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 727kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 737kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 747kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 757kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 768kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 778kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 788kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 798kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 808kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 819kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 829kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 839kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 849kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 860kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 870kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 880kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 890kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 901kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 911kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 921kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 931kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 942kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 952kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 962kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 972kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 983kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 993kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.0MB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.0MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.0MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.0MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.0MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.1MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.1MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.1MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.1MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.1MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.1MB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1MB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.1MB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.1MB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.1MB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.2MB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.2MB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.2MB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.2MB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.2MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.2MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.2MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.2MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.2MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.3MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.3MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.3MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.3MB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.3MB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.3MB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.3MB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.3MB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.3MB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.4MB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.4MB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.4MB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.4MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.4MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.4MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.4MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.4MB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.4MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.4MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.5MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.5MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.5MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.5MB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5MB 3.5MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "Successfully installed pip-20.1.1\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.30.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.5)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.17.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.7.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (49.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.18.5)\n",
            "Collecting split-folders\n",
            "  Downloading split_folders-0.3.1-py3-none-any.whl (6.2 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPL7mi6uYI3e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1163ee42-c720-4048-b741-b1f86042cee4"
      },
      "source": [
        "# Importovanie kniznic\n",
        "\n",
        "# Zakladne kniznice pre pracu\n",
        "import math, time, os, random, shutil\n",
        "\n",
        "# Pre dodatocne spracovanie \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL.Image\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from google.colab import drive\n",
        "\n",
        "mpl.rcParams['figure.figsize'] = (12, 5)\n",
        "\n",
        "# Pre neuronovu siet\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "import keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPgHBMuH-Rly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Nadefinovanie potrebnej plotovacej funkcie \n",
        "#Definicia pre vyplotenie jedneho obrazku\n",
        "\n",
        "def plotImage(img):\n",
        "    fig, axes = plt.subplots(1, 1, figsize=(5,5))\n",
        "    axes.imshow(img[0])\n",
        "    axes.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpWLiwADbz2X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "1db1a942-9ff5-45a8-b8e7-b6228f424399"
      },
      "source": [
        "# Namapuje google drive\n",
        "\n",
        "!mkdir raw_data \n",
        "drive.mount('raw_data/')\n",
        "path = '/content/raw_data/My Drive/Space::Lab/ML_Left/'\n",
        "print(\"Cesta k RAW datam je: \" + path)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at raw_data/\n",
            "Cesta k RAW datam je: /content/raw_data/My Drive/Space::Lab/ML_Left/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3HEcRh7kZUG",
        "colab_type": "text"
      },
      "source": [
        "**Nacitanie zoznamu a preorganizovanie obrazkov**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X03IX3IVFEXE",
        "colab_type": "text"
      },
      "source": [
        "**Praca na obrazkoch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIBTKdSbdF35",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "c1f69aec-dc62-4000-a616-d442bc9a47ea"
      },
      "source": [
        "# A tereaz pekne odznovu\n",
        "\n",
        "train_dir = \"/content/raw_data/My Drive/Space::Lab/ML_Left/old/train\"\n",
        "validation_dir = \"/content/raw_data/My Drive/Space::Lab/ML_Left/old/validation\"\n",
        "\n",
        "\n",
        "# Poscita pocet obrazkov\n",
        "\n",
        "num_nothing_tr    =   len(os.listdir(train_dir+\"/nothing\"))\n",
        "num_event_tr      =   len(os.listdir(train_dir+\"/event\"))\n",
        "\n",
        "num_nothing_val   =   len(os.listdir(validation_dir+\"/nothing\"))\n",
        "num_event_val     =   len(os.listdir(validation_dir+\"/event\"))\n",
        "\n",
        "total_train       =   num_nothing_tr + num_event_tr\n",
        "total_val         =   num_nothing_val + num_event_val\n",
        "\n",
        "# Vypise ciselne pocty event-ov\n",
        "print(\"--\")\n",
        "print('total training nothing images:', num_nothing_tr)\n",
        "print('total training event images:', num_event_tr)\n",
        "print(\"--\")\n",
        "print('total validation nothing images:', num_nothing_val)\n",
        "print('total validation event images:', num_event_val)\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)\n",
        "\n",
        "\n",
        "#Nastavuje vlastnosti obrazkov a modelu\n",
        "\n",
        "batch_size    =   55\n",
        "epochs        =   10\n",
        "IMG_HEIGHT    =   200\n",
        "IMG_WIDTH     =   250\n",
        "# Moje rozlisenie 250 x 200  /// Povodne rozlisenie 150 x 150\n",
        "\n",
        "# Augmentacie obrazkov\n",
        "\n",
        "image_gen_train = ImageDataGenerator(\n",
        "                    rescale               =   1./255,       #preskalovanie\n",
        "                    rotation_range        =   0,            #rotacia okolo stredu\n",
        "                    width_shift_range     =   0.0,         #posunutie/roztiahnutie do sirky \n",
        "                    height_shift_range    =   0.0,         #posunutie/roztiahnutie do vysky\n",
        "                    horizontal_flip       =   True,         #preklopenie obrazka okolo |\n",
        "                    zoom_range            =   0.0,          #priblizenie obrazu\n",
        "                    )\n",
        "\n",
        "image_gen_train = ImageDataGenerator(rescale=1./255)\n",
        "image_gen_val = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Nacitanie trenovacich obrazkov do modelu\n",
        "\n",
        "train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n",
        "                                                     directory=train_dir,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='binary',\n",
        "                                                     #color_mode='grayscale'\n",
        "                                                     )\n",
        "\n",
        "\n",
        "# Vygenreuje validovacie obrazky pre neuronku\n",
        "\n",
        "val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,\n",
        "                                                 directory=validation_dir,\n",
        "                                                 target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                 class_mode='binary',\n",
        "                                                 #color_mode='grayscale'\n",
        "                                                 )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--\n",
            "total training nothing images: 2646\n",
            "total training event images: 483\n",
            "--\n",
            "total validation nothing images: 400\n",
            "total validation event images: 50\n",
            "--\n",
            "Total training images: 3129\n",
            "Total validation images: 450\n",
            "Found 3129 images belonging to 2 classes.\n",
            "Found 450 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-bdAOXhUgCo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f5e854ab-c46c-483f-bdb2-9997665c0cb4"
      },
      "source": [
        "#Podme to navazit \n",
        "\n",
        "weight_for_0 = (1 / 483)*(3129)/2.0 \n",
        "weight_for_1 = (1 / 2646)*(3129)/2.0\n",
        "\n",
        "print(\"weight_for_0 = \"+str(weight_for_0))\n",
        "print(\"weight_for_1 = \"+str(weight_for_1))\n",
        "\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weight_for_0 = 3.239130434782609\n",
            "weight_for_1 = 0.5912698412698413\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxGsZFjLFJa8",
        "colab_type": "text"
      },
      "source": [
        "**Praca na modeli**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oa_VIHm0tj_1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "8f11f764-902d-4df3-f65d-99ddb9aa3140"
      },
      "source": [
        "# Načítanie Cerberus modelu\n",
        "\n",
        "tleia_model_cerberus = tf.keras.models.load_model(path+\"/tleia_model_cerberus.h5\")\n",
        "\n",
        "\"\"\"\n",
        "# Vytvorenie modelu Huge\n",
        "\n",
        "tleia_model_cerberus = Sequential([\n",
        "    Conv2D(16, 3, padding='same', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3), activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Dropout(0.05),\n",
        "\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Dropout(0.05),\n",
        "\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Dropout(0.05),\n",
        "\n",
        "    Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Dropout(0.05),\n",
        "\n",
        "    Flatten(),\n",
        "\n",
        "    Dense(1024),\n",
        "    Dropout(0.05),\n",
        "\n",
        "    Dense(1024, activation='relu'),\n",
        "    Dropout(0.05),\n",
        "\n",
        "    Dense(1)\n",
        "    \n",
        "    ])\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n# Vytvorenie modelu Huge\\n\\ntleia_model_cerberus = Sequential([\\n    Conv2D(16, 3, padding='same', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3), activation='relu'),\\n    MaxPooling2D(),\\n    Dropout(0.05),\\n\\n    Conv2D(32, 3, padding='same', activation='relu'),\\n    MaxPooling2D(),\\n    Dropout(0.05),\\n\\n    Conv2D(64, 3, padding='same', activation='relu'),\\n    MaxPooling2D(),\\n    Dropout(0.05),\\n\\n    Conv2D(128, 3, padding='same', activation='relu'),\\n    MaxPooling2D(),\\n    Dropout(0.05),\\n\\n    Flatten(),\\n\\n    Dense(1024),\\n    Dropout(0.05),\\n\\n    Dense(1024, activation='relu'),\\n    Dropout(0.05),\\n\\n    Dense(1)\\n    \\n    ])\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XupPg9dPBrg5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 756
        },
        "outputId": "06815b6a-46cd-4ef6-c17d-4c4648f0ead1"
      },
      "source": [
        "# Skompilovanie modelu a jeho sumarizacia Huge\n",
        "\n",
        "METRICS = [\n",
        "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      keras.metrics.Precision(name='precision'),\n",
        "      keras.metrics.TruePositives(name='TN'),\n",
        "      keras.metrics.FalsePositives(name='FN'),\n",
        "      keras.metrics.TrueNegatives(name='TP'),\n",
        "      keras.metrics.FalseNegatives(name='FP'), \n",
        "      #keras.metrics.Recall(name='recall'),\n",
        "      #keras.metrics.AUC(name='auc'),\n",
        "      #keras.metrics.SpecificityAtSensitivity(0.25, name=\"SpecATSen\")\n",
        "      ]\n",
        "\n",
        "tleia_model_cerberus.compile(optimizer='adam',   #Podla porovnani najlepsi optimizer\n",
        "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                  metrics=METRICS) #['accuracy']\n",
        "\n",
        "tleia_model_cerberus.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_25 (Conv2D)           (None, 200, 250, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_25 (MaxPooling (None, 100, 125, 16)      0         \n",
            "_________________________________________________________________\n",
            "dropout_39 (Dropout)         (None, 100, 125, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 100, 125, 32)      4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_26 (MaxPooling (None, 50, 62, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_40 (Dropout)         (None, 50, 62, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 50, 62, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_27 (MaxPooling (None, 25, 31, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_41 (Dropout)         (None, 25, 31, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 25, 31, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_28 (MaxPooling (None, 12, 15, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_42 (Dropout)         (None, 12, 15, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 23040)             0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 1024)              23593984  \n",
            "_________________________________________________________________\n",
            "dropout_43 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dropout_44 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 1)                 1025      \n",
            "=================================================================\n",
            "Total params: 24,742,049\n",
            "Trainable params: 24,742,049\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ahzsn2FBxE5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "03ec0a37-f15f-4c72-bcbd-3d475b36eb23"
      },
      "source": [
        "# Ucenie neuronovej siete Huge\n",
        "\n",
        "history = tleia_model_cerberus.fit(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=total_train // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=total_val // batch_size,\n",
        "    class_weight=class_weight)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "56/56 [==============================] - 309s 6s/step - loss: 0.0060 - accuracy: 0.0059 - precision: 0.9984 - TN: 149710.9062 - FN: 241.0000 - TP: 26140.4102 - FP: 1169.5000 - val_loss: 0.1839 - val_accuracy: 0.0059 - val_precision: 0.9984 - val_TN: 151201.5000 - val_FN: 241.7500 - val_TP: 26401.1250 - val_FP: 1177.1250\n",
            "Epoch 2/10\n",
            "56/56 [==============================] - 307s 5s/step - loss: 0.0050 - accuracy: 0.0059 - precision: 0.9984 - TN: 152679.5781 - FN: 243.9286 - TP: 26676.5723 - FP: 1181.3214 - val_loss: 0.1758 - val_accuracy: 0.0058 - val_precision: 0.9984 - val_TN: 154176.1250 - val_FN: 246.5000 - val_TP: 26925.7500 - val_FP: 1187.1250\n",
            "Epoch 3/10\n",
            "56/56 [==============================] - 305s 5s/step - loss: 0.0035 - accuracy: 0.0058 - precision: 0.9984 - TN: 155677.2188 - FN: 247.0000 - TP: 27177.2500 - FP: 1191.1428 - val_loss: 0.1867 - val_accuracy: 0.0058 - val_precision: 0.9984 - val_TN: 157159.7500 - val_FN: 248.1250 - val_TP: 27445.6250 - val_FP: 1196.0000\n",
            "Epoch 4/10\n",
            "56/56 [==============================] - 307s 5s/step - loss: 0.0045 - accuracy: 0.0057 - precision: 0.9984 - TN: 158654.4844 - FN: 249.0000 - TP: 27698.6973 - FP: 1202.8214 - val_loss: 0.2682 - val_accuracy: 0.0057 - val_precision: 0.9984 - val_TN: 160137.2500 - val_FN: 249.8750 - val_TP: 27967.7500 - val_FP: 1208.6250\n",
            "Epoch 5/10\n",
            "56/56 [==============================] - 304s 5s/step - loss: 0.0321 - accuracy: 0.0057 - precision: 0.9984 - TN: 161615.6094 - FN: 251.8571 - TP: 28231.8574 - FP: 1223.8572 - val_loss: 0.1039 - val_accuracy: 0.0057 - val_precision: 0.9984 - val_TN: 163084.6250 - val_FN: 253.8750 - val_TP: 28497.8750 - val_FP: 1241.1250\n",
            "Epoch 6/10\n",
            "53/56 [===========================>..] - ETA: 14s - loss: 0.0073 - accuracy: 0.0057 - precision: 0.9985 - TN: 164502.6250 - FN: 255.0000 - TP: 28746.1328 - FP: 1248.7548"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vC5-mDvIdypT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5339021a-bf39-4ac3-e7fa-33e59bcc0469"
      },
      "source": [
        "# Ulozenie samotneho modeluHuge\n",
        " \n",
        "tleia_model_cerberus.save(\n",
        "    path+\"/tleia_model_cerberus/\", overwrite=True, \n",
        "    include_optimizer=True, save_format=True,\n",
        "    signatures=None, options=None)\n",
        "\n",
        "!pip install -q pyyaml h5py\n",
        "tleia_model_cerberus.save(path+\"/tleia_model_cerberus.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/raw_data/My Drive/Space::Lab/ML_Left//tleia_model_cerberus/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3renPnO_Uf_O",
        "colab_type": "text"
      },
      "source": [
        "Tuna zacina experimentovanie\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czj83aKXBnBF",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "#BEHEMOOOT model \n",
        "\n",
        "tleia_model_behemoth = tf.keras.applications.NASNetMobile(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), \n",
        "                                                          include_top=True, weights=None, \n",
        "                                                          input_tensor=None, pooling=\"avg\", classes=1000)\n",
        "\n",
        "METRICS = [\n",
        "      keras.metrics.TruePositives(name='TN'),\n",
        "      keras.metrics.FalsePositives(name='FN'),\n",
        "      keras.metrics.TrueNegatives(name='TP'),\n",
        "      keras.metrics.FalseNegatives(name='FP'), \n",
        "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      keras.metrics.Precision(name='precision'),\n",
        "      keras.metrics.Recall(name='recall'),\n",
        "      keras.metrics.AUC(name='auc'),\n",
        "      #keras.metrics.SpecificityAtSensitivity(0.4, name=\"SpecATSen\")\n",
        "      ]\n",
        "     \n",
        "tleia_model_behemoth.compile(optimizer='adam',   \n",
        "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                  metrics=METRICS)\n",
        "\n",
        "tleia_model_behemoth_sequential = Sequential()\n",
        "tleia_model_behemoth_sequential.add(tleia_model_behemoth)\n",
        "tleia_model_behemoth_sequential.add(Dense(1000, activation='tanh'))\n",
        "tleia_model_behemoth_sequential.add(Dense(1, activation='relu'))\n",
        "\n",
        "tleia_model_behemoth_sequential.compile(optimizer='adam',   \n",
        "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                  metrics=METRICS)\n",
        "\n",
        "tleia_model_behemoth_sequential.summary()\n",
        "------------------------\n",
        "history = tleia_model_behemoth_sequential.fit(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=total_train // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=total_val // batch_size,\n",
        "    class_weight=class_weight)\n",
        "------------------------------\n",
        "#Leviathan model  \n",
        "\n",
        "tleia_model_leviathan = tf.keras.applications.Xception(\n",
        "    include_top=True,\n",
        "    weights=None,\n",
        "    input_tensor=None,\n",
        "    input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n",
        "    pooling=None,\n",
        "    classes=1,\n",
        "    classifier_activation=\"softmax\",)\n",
        "\n",
        "tleia_model_leviathan.compile(optimizer='adam',   \n",
        "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "tleia_model_leviathan.summary()\n",
        "--------------------------\n",
        "history = tleia_model_leviathan.fit(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=total_train // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=total_val // batch_size,\n",
        "    class_weight=class_weight)\n",
        "---------------------------\n",
        "#Hydra model \n",
        "\n",
        "#tleia_model_hydra = tf.keras.applications.NASNetLarge(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), include_top=True, weights=None, input_tensor=None, pooling=None, classes=1)\n",
        "\n",
        "tleia_model_hydra.compile(optimizer='adam',   \n",
        "                  loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "tleia_model_hydra.summary()\n",
        "--------------------------------\n",
        "history = tleia_model_hydra.fit(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=total_train // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=total_val // batch_size \n",
        "    )\n",
        "----------------------------------\n",
        "#CERBERUS model \n",
        "\n",
        "tleia_model_cerberus = tf.keras.applications.VGG19(\n",
        "    include_top=True,\n",
        "    weights=None,\n",
        "    input_tensor=None,\n",
        "    input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n",
        "    pooling=None,\n",
        "    classes=1,\n",
        "    classifier_activation=\"softmax\")\n",
        "\n",
        "tleia_model_cerberus.compile(optimizer='adam',   \n",
        "                  loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                  metrics=[tf.keras.metrics.Accuracy(),\n",
        "                           tf.keras.metrics.Precision()])\n",
        "\n",
        "tleia_model_cerberus.summary()\n",
        "----------------------------\n",
        "history = tleia_model_cerberus.fit(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=total_train // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=total_val // batch_size )\n",
        "-----------------------------------\n",
        "# Ulozenie oboch modelov (Behemoth)\n",
        "\n",
        "# Behemoth  = NasNetMobile\n",
        "# Leviathan = Xception\n",
        "# Hydra     = NasNetLarge\n",
        "\n",
        "tleia_model_behemoth.save(\n",
        "    path+\"/tleia_model_behemoth/\", overwrite=True, include_optimizer=True, save_format=True,\n",
        "    signatures=None, options=None)\n",
        "\n",
        "\n",
        "tleia_model_behemoth.save(path+\"/tleia_model_behemoth.h5\")\n",
        "--------------------------------\n",
        "# Ulozenie oboch modelov (leviathan)\n",
        "\n",
        "tleia_model_leviathan.save(\n",
        "    path+\"/tleia_model_leviathan/\", overwrite=True, include_optimizer=True, save_format=True,\n",
        "    signatures=None, options=None)\n",
        "\n",
        "tleia_model_leviathan.save(path+\"/tleia_model_leviathan.h5\")\n",
        "--------------------------------\n",
        "# Ulozenie modelu Hydra\n",
        "\n",
        "tleia_model_hydra.save(\n",
        "    path+\"/tleia_model_hydra/\", overwrite=True, include_optimizer=True, save_format=True,\n",
        "    signatures=None, options=None)\n",
        "\n",
        "tleia_model_hydra.save(path+\"/tleia_model_hydra.h5\")\n",
        "-----------------------------------\n",
        "#Nacita modely\n",
        "\n",
        "tleia_model_behemoth = tf.keras.models.load_model(path+\"/tleia_model_behemoth/\")\n",
        "------------------------------\n",
        "#Nacita modely\n",
        "\n",
        "tleia_model_leviathan = tf.keras.models.load_model(path+\"/tleia_model_leviathan/\")\n",
        "--------------------------------------------\n",
        "#Nacita modely\n",
        "\n",
        "tleia_model_hydra = tf.keras.models.load_model(path+\"/tleia_model_hydra/\")\n",
        "---------------------------------------\n",
        "```\n",
        "\n"
      ]
    }
  ]
}
